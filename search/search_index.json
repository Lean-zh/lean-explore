{"config":{"lang":["en","zh"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"LeanExplore Documentation","text":"<p>Welcome to the LeanExplore documentation! This is your central hub for understanding how to navigate and utilize the LeanExplore Python package effectively. Find the project on GitHub.</p> <p>LeanExplore is a Python package offering a powerful semantic search engine and versatile toolkit for Lean 4 projects. It assists Lean users in efficiently finding code through semantic search\u2014leveraging vector-based similarity from embeddings of both formal Lean statements and their informal counterparts\u2014and in exploring the dependencies of these statements to gain deeper insights. LeanExplore serves as a valuable component for building custom tools, enhancing proof development workflows, and integrating Lean's structured knowledge into AI applications.</p>"},{"location":"#core-features","title":"Core Features","text":"<ul> <li>Versatile Search Capabilities: Find Lean statements with precision. Search semantically to discover code based on conceptual meaning, or search directly by known declaration names for targeted results.</li> <li>Interactive AI Assistance: Utilize an AI-powered chat interface (via the CLI) to ask questions about Lean code, receive explanations, and explore dependencies conversationally.</li> <li>Flexible Data Backends: Choose to operate with a fully local dataset for complete offline access and control, or leverage our convenient remote API for zero-setup searching capabilities.</li> <li>Comprehensive CLI Toolkit: Manage local data, configure settings, perform searches, and launch AI interactions directly from your terminal.</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>The best way to begin your journey with LeanExplore is by following our Quickstart Guide. This guide will walk you through the initial setup and your first key interactions with the package, ensuring you get up and running smoothly.</p> <p>Once you're familiar with the basics, you can explore these areas for more detailed information on specific functionalities:</p> <ul> <li>Using the Command-Line Interface (CLI): Master the full range of available commands and options for various tasks from data management to AI chat.</li> <li>Performing Searches: Learn how to search programmatically, whether you're using local data resources or interacting with the remote API.</li> <li>MCP (AI Agents): Discover how to integrate LeanExplore with AI agent systems for advanced applications and custom tool development.</li> </ul> <p>For a detailed look at every function, class, and module within the LeanExplore package, including their parameters and return types, please browse the API Reference section available in the sidebar.</p>"},{"location":"cli/search/","title":"Performing Searches with LeanExplore","text":"<p>LeanExplore offers flexible and powerful ways to search for Lean mathematical statements and definitions, catering to different needs and workflows. This guide details how to perform searches programmatically using either the remote LeanExplore API for immediate access or local data resources for offline capabilities. These methods allow you to integrate LeanExplore's search engine into your custom Python tools or analyses.</p>"},{"location":"cli/search/#contents","title":"Contents","text":"<ul> <li>Searching via the Remote API</li> <li>Prerequisites</li> <li>Programmatic Access (Asynchronous)</li> <li>Internal Usage by CLI</li> <li>Searching with Local Data</li> <li>Prerequisites</li> <li>Programmatic Access</li> <li>Internal Usage by CLI</li> </ul>"},{"location":"cli/search/#searching-via-the-remote-api","title":"Searching via the Remote API","text":"<p>Using the remote API is a quick way to get started, as it offloads data hosting and search computation to the LeanExplore servers. All you need is an API key and an internet connection. The methods in the API client are asynchronous. For use in IPython or Jupyter, top-level <code>await</code> can often be used directly.</p>"},{"location":"cli/search/#prerequisites","title":"Prerequisites","text":"<ul> <li>The <code>lean_explore</code> Python package installed (<code>pip install lean-explore</code>). This includes the <code>httpx</code> library required by the API client.</li> <li>Your personal LeanExplore API key. You can obtain one from leanexplore.com/api-keys.</li> <li>This API key should be configured using the CLI for easy loading:   <pre><code>leanexplore configure api-key YOUR_API_KEY_HERE\n</code></pre>   Alternatively, set the <code>LEANEXPLORE_API_KEY</code> environment variable.</li> </ul>"},{"location":"cli/search/#programmatic-access-asynchronous","title":"Programmatic Access (Asynchronous)","text":""},{"location":"cli/search/#1-initializing-the-api-client","title":"1. Initializing the API Client","text":"<p>Import necessary modules and initialize the client. This assumes your API key is configured.</p> <pre><code>import asyncio\nfrom lean_explore.api.client import Client\nfrom lean_explore.cli import config_utils\n\n# Load API key (ensure it's configured via CLI or ENV variable)\napi_key = config_utils.load_api_key() \nclient = Client(api_key=api_key)\nprint(\"API Client initialized.\")\n</code></pre>"},{"location":"cli/search/#2-performing-a-search","title":"2. Performing a Search","text":"<p>Use the <code>client.search()</code> method. It returns an <code>APISearchResponse</code> object. (Requires <code>client</code> from step 1).</p> <pre><code># Define query and limit for displaying results\nquery_str_api = \"fundamental theorem of calculus\"\ndisplay_limit_api = 3\n\n# Perform the search (use 'await' in an async context e.g. IPython, Jupyter, or async script)\nsearch_response_api = await client.search(query=query_str_api)\n\nprint(f\"\\nFound {search_response_api.count} API results for '{query_str_api}':\")\nfor item_api in search_response_api.results[:display_limit_api]:\n    name_api = (item_api.primary_declaration.lean_name\n                if item_api.primary_declaration else \"N/A\")\n    print(f\"  ID: {item_api.id}, Name: {name_api}\")\n    print(f\"    File: {item_api.source_file}:{item_api.range_start_line}\")\n\n# Example: Get ID of the first result, assuming results are present\napi_first_result_id = search_response_api.results[0].id\nprint(f\"ID of the first API result: {api_first_result_id}\")\n</code></pre>"},{"location":"cli/search/#3-retrieving-a-statement-group-by-id","title":"3. Retrieving a Statement Group by ID","text":"<p>Use <code>client.get_by_id()</code>. (Requires <code>client</code> and <code>api_first_result_id</code> from previous steps).</p> <pre><code># Use the ID obtained from the search results\nitem_details_api = await client.get_by_id(group_id=api_first_result_id)\n\nname_details_api = (item_details_api.primary_declaration.lean_name\n                    if item_details_api.primary_declaration else \"N/A\")\nprint(f\"\\nDetails for API Statement Group ID {item_details_api.id}: Name: {name_details_api}\")\n# print(f\"  Statement: {item_details_api.statement_text}\")\n</code></pre>"},{"location":"cli/search/#4-fetching-dependencies","title":"4. Fetching Dependencies","text":"<p>Use <code>client.get_dependencies()</code>. (Requires <code>client</code> and <code>api_first_result_id</code>).</p> <pre><code># Use the ID obtained from the search results\ndeps_response_api = await client.get_dependencies(group_id=api_first_result_id)\n\nprint(f\"\\nAPI Dependencies for Group ID {deps_response_api.source_group_id}\\n  ({deps_response_api.count} found):\")\nfor citation_api in deps_response_api.citations:\n    name_deps_api = (citation_api.primary_declaration.lean_name\n                     if citation_api.primary_declaration else \"N/A\")\n    print(f\"  - Dep ID: {citation_api.id}, Name: {name_deps_api}\")\n</code></pre> <p>Note on Running Async Code: The <code>await</code> keyword is used for API calls. In a standalone Python script, you would typically wrap these calls in an <code>async def</code> function and run it using <code>asyncio.run()</code>. In environments like IPython 7.0+ or Jupyter notebooks, top-level <code>await</code> is often supported directly.</p>"},{"location":"cli/search/#internal-usage-by-cli","title":"Internal Usage by CLI","text":"<p>The LeanExplore CLI commands such as <code>leanexplore search</code>, <code>get</code>, <code>dependencies</code>, and <code>leanexplore chat --backend api</code> (which is the default for chat if an API key is set) all utilize this <code>lean_explore.api.client.Client</code> internally.</p>"},{"location":"cli/search/#searching-with-local-data","title":"Searching with Local Data","text":"<p>This mode allows you to perform searches directly on your machine using a local dataset. It leverages a SQLite database for structured information, a FAISS vector index for efficient semantic matching, and local sentence embedding models to process your queries. This is ideal for offline use, custom data analysis, or when you prefer full control over the data assets.</p>"},{"location":"cli/search/#prerequisites_1","title":"Prerequisites","text":"<ul> <li>The <code>lean_explore</code> Python package installed.</li> <li>The local data toolchain must be downloaded and available. You can do this using the CLI command:   <pre><code>leanexplore data fetch\n</code></pre>   This ensures the database and FAISS index are present in the expected location (typically <code>~/.lean_explore/data/toolchains/&lt;version&gt;/</code>).</li> </ul>"},{"location":"cli/search/#programmatic-access","title":"Programmatic Access","text":""},{"location":"cli/search/#1-initializing-the-local-service","title":"1. Initializing the Local Service","text":"<p>Import and instantiate the <code>lean_explore.local.service.Service</code> class. This assumes data files are correctly downloaded.</p> <pre><code>from lean_explore.local.service import Service\n\n# Assumes Service() initializes successfully (data files are present)\nservice_instance = Service()\nprint(\"LocalService initialized successfully.\")\n</code></pre>"},{"location":"cli/search/#2-performing-a-search_1","title":"2. Performing a Search","text":"<p>Use the <code>service.search()</code> method. It returns an <code>APISearchResponse</code> object. (Requires <code>service_instance</code> from step 1).</p> <pre><code># Define query and limit\nquery_str_local = \"ring definition\"\nlimit_for_local = 3\n\nsearch_response_local = service_instance.search(\n    query=query_str_local, \n    limit=limit_for_local\n)\n\nprint(f\"\\nFound {search_response_local.count} local results for '{query_str_local}':\")\nfor item_local in search_response_local.results: # Already limited by service.search\n    name_local = (item_local.primary_declaration.lean_name\n                  if item_local.primary_declaration else \"N/A\")\n    print(f\"  ID: {item_local.id}, Name: {name_local}\")\n    print(f\"    File: {item_local.source_file}:{item_local.range_start_line}\")\n\n# Example: Get ID of the first result, assuming results are present\nlocal_first_result_id = search_response_local.results[0].id\nprint(f\"ID of the first local result: {local_first_result_id}\")\n</code></pre>"},{"location":"cli/search/#3-retrieving-a-statement-group-by-id_1","title":"3. Retrieving a Statement Group by ID","text":"<p>Use <code>service.get_by_id()</code>. (Requires <code>service_instance</code> and <code>local_first_result_id</code>).</p> <pre><code># Use the ID obtained from the local search results\nitem_details_local = service_instance.get_by_id(\n    group_id=local_first_result_id\n)\n\nname_details_local = (item_details_local.primary_declaration.lean_name\n                      if item_details_local.primary_declaration else \"N/A\")\nprint(f\"\\nDetails for Local Statement Group ID {item_details_local.id}: Name: {name_details_local}\")\n# print(f\"  Statement: {item_details_local.statement_text}\")\n</code></pre>"},{"location":"cli/search/#4-fetching-dependencies_1","title":"4. Fetching Dependencies","text":"<p>Use <code>service.get_dependencies()</code>. (Requires <code>service_instance</code> and <code>local_first_result_id</code>).</p> <pre><code># Use the ID obtained from the local search results\ndeps_response_local = service_instance.get_dependencies(\n    group_id=local_first_result_id\n)\n\nprint(f\"\\nLocal Dependencies for Group ID {deps_response_local.source_group_id}\\n  ({deps_response_local.count} found):\")\nfor citation_local in deps_response_local.citations:\n    name_deps_local = (citation_local.primary_declaration.lean_name\n                       if citation_local.primary_declaration else \"N/A\")\n    print(f\"  - Dep ID: {citation_local.id}, Name: {name_deps_local}\")\n</code></pre>"},{"location":"cli/search/#internal-usage-by-cli_1","title":"Internal Usage by CLI","text":"<p>The LeanExplore CLI commands <code>leanexplore chat --backend local</code> and <code>leanexplore mcp serve --backend local</code> make use of this <code>lean_explore.local.service.Service</code> class to interact with your local data toolchain.</p>"},{"location":"cli/usage/","title":"Using the LeanExplore CLI","text":"<p>The LeanExplore Command-Line Interface (CLI), invoked using the <code>leanexplore</code> command, is your primary tool for interacting with the LeanExplore ecosystem. It empowers you to configure settings, manage local data, search the LeanExplore API directly, explore code with an AI assistant, and control the Model Context Protocol (MCP) server for more advanced integrations.</p>"},{"location":"cli/usage/#contents","title":"Contents","text":"<ul> <li>Understanding CLI Basics</li> <li>Getting Started: Initial Setup</li> <li>Configuring Your API Keys</li> <li>(Optional) Preparing for Local Data Exploration</li> <li>Finding and Inspecting Lean Code (via API)</li> <li>Searching for Lean Statements</li> <li>Viewing Detailed Information</li> <li>Exploring Code Dependencies</li> <li>Interactive Exploration with the AI Chat Assistant</li> <li>Launching the Chat Session</li> <li>Understanding Key Chat Options</li> <li>Integrating with AI Agents via the MCP Server</li> <li>Running the Server</li> <li>Key Server Options</li> </ul>"},{"location":"cli/usage/#understanding-cli-basics","title":"Understanding CLI Basics","text":"<p>Most CLI commands follow the structure: <code>leanexplore [OPTIONS] COMMAND [ARGS]...</code>. To get help at any point, whether for the main command or a specific subcommand, simply append <code>--help</code>:</p> <pre><code>leanexplore --help\n</code></pre> <pre><code>leanexplore configure --help\n</code></pre> <pre><code>leanexplore data fetch --help\n</code></pre>"},{"location":"cli/usage/#getting-started-initial-setup","title":"Getting Started: Initial Setup","text":"<p>Before diving into all of LeanExplore's features, a few initial setup steps can ensure everything runs smoothly, especially when interacting with online services or the AI assistant.</p>"},{"location":"cli/usage/#configuring-your-api-keys","title":"Configuring Your API Keys","text":"<p>LeanExplore uses API keys to authenticate access to certain services. These are stored securely in a local configuration file once set up.</p> <p>LeanExplore API Key: This key is essential for features that communicate with the remote LeanExplore API, such as direct searches (<code>search</code>, <code>get</code>, <code>dependencies</code> commands) and using the AI chat with its default API backend.</p> <p>You can obtain your LeanExplore API key from https://www.leanexplore.com/api-keys. Once you have it, configure it by running:</p> <pre><code>leanexplore configure api-key\n</code></pre> <p>You will be prompted to enter your key. This is typically a one-time setup.</p> <p>OpenAI API Key: If you plan to use the AI-powered chat features (<code>leanexplore chat</code>), you'll also need an OpenAI API key. Configure it with:</p> <pre><code>leanexplore configure openai-key\n</code></pre> <p>Follow the prompts to enter your OpenAI key.</p>"},{"location":"cli/usage/#optional-preparing-for-local-data-exploration","title":"(Optional) Preparing for Local Data Exploration","text":"<p>For users who prefer to work offline or have direct control over the dataset, LeanExplore supports a local data toolchain. This involves downloading the necessary data assets to your machine.</p> <p>To download and set up the primary local data toolchain, use the command:</p> <pre><code>leanexplore data fetch\n</code></pre> <p>This command fetches the SQLite database (containing Lean project information), FAISS search indexes for semantic search, and associated mapping files. These are installed into a local directory, typically within <code>~/.lean_explore/data/toolchains/</code>.</p> <p>Note: The data toolchain can be several gigabytes. The initial download may take some time depending on your internet connection. This step is a prerequisite for using features that rely on a local backend, such as <code>leanexplore chat --backend local</code> or <code>leanexplore mcp serve --backend local</code>.</p>"},{"location":"cli/usage/#finding-and-inspecting-lean-code-via-api","title":"Finding and Inspecting Lean Code (via API)","text":"<p>Once your LeanExplore API key is configured, you can directly query the remote API to find and inspect Lean statements. These commands provide quick access to the wealth of information indexed by LeanExplore.</p>"},{"location":"cli/usage/#searching-for-lean-statements","title":"Searching for Lean Statements","text":"<p>To search for Lean statement groups based on a natural language query, use the <code>leanexplore search</code> command:</p> <pre><code>leanexplore search \"your query string here\" [OPTIONS]\n</code></pre> <p>For example, to find statements related to the \"fundamental theorem of calculus\", limit the results, and filter by the \"Mathlib\" package:</p> <pre><code>leanexplore search \"fundamental theorem of calculus\" --package Mathlib --limit 3\n</code></pre> <p>Key Options for Searching:</p> <ul> <li><code>QUERY_STRING</code>: Your search terms. Enclose in quotes if it contains spaces.</li> <li><code>--package TEXT</code> (or <code>-p TEXT</code>): Filter results by specific package names (e.g., <code>Mathlib</code>, <code>Std</code>). This option can be used multiple times to include several packages.</li> <li><code>--limit INTEGER</code> (or <code>-n INTEGER</code>): Specify the maximum number of search results to display. Defaults to 5.</li> </ul> <p>The command will display a list of matching statement groups, including their ID, Lean name, source file location, and relevant code or docstring snippets.</p>"},{"location":"cli/usage/#viewing-detailed-information","title":"Viewing Detailed Information","text":"<p>If you have a specific statement group ID (often obtained from search results), you can retrieve its full details using <code>leanexplore get</code>:</p> <pre><code>leanexplore get &lt;GROUP_ID&gt;\n</code></pre> <p>For instance:</p> <pre><code>leanexplore get 12345\n</code></pre> <p>This shows comprehensive information for the group, such as its full statement text, docstring, and any informal descriptions, usually presented in easy-to-read formatted panels.</p>"},{"location":"cli/usage/#exploring-code-dependencies","title":"Exploring Code Dependencies","text":"<p>To understand how a statement group connects to others, you can fetch its direct dependencies (items it cites) using <code>leanexplore dependencies</code>:</p> <pre><code>leanexplore dependencies &lt;GROUP_ID&gt;\n</code></pre> <p>Example:</p> <pre><code>leanexplore dependencies 12345\n</code></pre> <p>This command lists the statement groups that the specified group depends on, typically in a table format showing each dependency's ID, Lean name, and source location.</p>"},{"location":"cli/usage/#interactive-exploration-with-the-ai-chat-assistant","title":"Interactive Exploration with the AI Chat Assistant","text":"<p>LeanExplore provides an AI-powered chat assistant (<code>leanexplore chat</code>) for a conversational way to search, understand, and explore Lean code.</p> <p>Prerequisites:</p> <ul> <li>Your OpenAI API key must be configured (using <code>leanexplore configure openai-key</code>).</li> <li>For the default API backend: Your LeanExplore API key must be configured.</li> <li>For the local backend: Your local data toolchain must be fetched (using <code>leanexplore data fetch</code>).</li> </ul>"},{"location":"cli/usage/#launching-the-chat-session","title":"Launching the Chat Session","text":"<p>To start a chat session using the default API backend (recommended for most users, providing access to the latest data):</p> <pre><code>leanexplore chat\n</code></pre> <p>If you've set up local data and prefer to use that (e.g., for offline access):</p> <pre><code>leanexplore chat --backend local\n</code></pre>"},{"location":"cli/usage/#understanding-key-chat-options","title":"Understanding Key Chat Options","text":"<ul> <li><code>--backend {api|local}</code> (alias: <code>-lb</code>): Specifies the data source for the AI's tools.</li> <li><code>api</code> (default): The agent queries the remote LeanExplore API.</li> <li><code>local</code>: The agent uses your downloaded local data.</li> <li><code>--lean-api-key TEXT</code>: (Optional) If using the API backend, you can provide a LeanExplore API key for the current session, overriding any configured key.</li> <li><code>--debug</code>: Enables detailed debug logging for both the chat client and the underlying MCP server it manages. This is useful for troubleshooting.</li> </ul> <p>Once in the chat, you can ask the assistant to perform tasks like \"Find definitions of 'monoid' in Mathlib\" or \"Show me the dependencies of <code>Nat.add</code>\".</p>"},{"location":"cli/usage/#integrating-with-ai-agents-via-the-mcp-server","title":"Integrating with AI Agents via the MCP Server","text":"<p>This is an advanced feature for developers aiming to integrate LeanExplore's search and retrieval capabilities as tools within their own custom AI agent applications or other programmatic setups.</p> <p>The <code>leanexplore mcp serve</code> command launches the LeanExplore Model Context Protocol (MCP) server. This server communicates via standard input/output (stdio) using JSON-RPC 2.0 and exposes LeanExplore's functionalities as \"tools\" that an MCP-compatible agent client can call.</p>"},{"location":"cli/usage/#running-the-server","title":"Running the Server","text":"<p>To serve tools using the remote API backend (ensure LeanExplore API key is configured or provide it with <code>--api-key</code>):</p> <pre><code>leanexplore mcp serve --backend api\n</code></pre> <p>To serve tools using your local data backend (ensure local data has been fetched):</p> <pre><code>leanexplore mcp serve --backend local\n</code></pre>"},{"location":"cli/usage/#key-server-options","title":"Key Server Options","text":"<ul> <li><code>--backend {api|local}</code> (alias: <code>-b</code>): Determines if the server's tools will use the remote API or local data. Defaults to <code>api</code>.</li> <li><code>--api-key TEXT</code>: (Required if <code>--backend api</code> and no key is configured) Directly provide the LeanExplore API key for the server to use.</li> </ul> <p>Note: The <code>leanexplore chat</code> command internally manages an instance of this MCP server. Running <code>leanexplore mcp serve</code> directly is typically for scenarios where you are connecting a different MCP client or agent framework.</p> <p>By familiarizing yourself with these commands and workflows, you can effectively leverage the LeanExplore CLI for your mathematical explorations and development in Lean 4.</p>"},{"location":"getting-started/quickstart/","title":"Quickstart Guide","text":"<p>Welcome to the LeanExplore Quickstart Guide! This page will walk you through the essential first steps to get up and running with LeanExplore using its powerful remote API and Command-Line Interface (CLI). Our goal is to help you perform your first meaningful actions quickly.</p>"},{"location":"getting-started/quickstart/#prerequisites-installation","title":"Prerequisites: Installation","text":"<p>Before you begin, ensure you have LeanExplore installed. If not, you can install it using pip:</p> <pre><code>pip install lean-explore\n</code></pre> <p>This guide focuses on using the LeanExplore API, which is the default mode for many commands and provides a zero-setup way to access search and AI features once your API keys are configured.</p>"},{"location":"getting-started/quickstart/#step-1-obtain-your-leanexplore-api-key","title":"Step 1: Obtain Your LeanExplore API Key","text":"<p>To interact with the LeanExplore API, you'll need a personal API key. This key authenticates your requests to our servers. If you don't have one, please visit https://www.leanexplore.com/api-keys to sign up or log in and obtain your API key.</p>"},{"location":"getting-started/quickstart/#step-2-configure-your-leanexplore-api-key","title":"Step 2: Configure Your LeanExplore API Key","text":"<p>Once you have your API key, the next step is to configure it with the LeanExplore CLI. This will save your key securely for future use, so you don't have to enter it every time.</p> <p>Run the following command in your terminal:</p> <pre><code>leanexplore configure api-key\n</code></pre> <p>You will be prompted to paste your API key. This is a one-time setup. If you've already done this, you can proceed to the next step.</p>"},{"location":"getting-started/quickstart/#step-3-perform-your-first-search","title":"Step 3: Perform Your First Search","text":"<p>With your API key configured, you're ready to perform your first search directly from the command line. Let's try searching for a well-known theorem:</p> <pre><code>leanexplore search \"fundamental theorem of calculus\"\n</code></pre> <p>You should see a list of relevant Lean statements matching your query, along with details like their source file, line number, and a snippet of the code. This demonstrates the direct search capability of LeanExplore via its API.</p>"},{"location":"getting-started/quickstart/#step-4-try-the-ai-chat-via-api","title":"Step 4: Try the AI Chat (via API)","text":"<p>LeanExplore also offers an AI-powered chat assistant for a more interactive way to explore Lean code. By default, if your LeanExplore API key is configured, the chat will use the API backend. For the AI capabilities, you'll also need an OpenAI API key.</p>"},{"location":"getting-started/quickstart/#4a-configure-openai-api-key-if-needed","title":"4a. Configure OpenAI API Key (If Needed)","text":"<p>If you haven't set up your OpenAI API key with LeanExplore yet, run:</p> <pre><code>leanexplore configure openai-key\n</code></pre> <p>Follow the prompts. If this key is already configured, you can skip this sub-step.</p>"},{"location":"getting-started/quickstart/#4b-start-the-chat-session","title":"4b. Start the Chat Session","text":"<p>Now, launch the AI chat assistant:</p> <pre><code>leanexplore chat\n</code></pre> <p>Since your LeanExplore API key is configured and <code>--backend api</code> is the default, the assistant will use the remote API for its Lean-specific knowledge.</p>"},{"location":"getting-started/quickstart/#4c-ask-a-question","title":"4c. Ask a Question","text":"<p>Once the chat interface loads and the assistant is ready, try asking it to find a specific definition and its context, for example:</p> <pre><code>You: Find the formal statement for the 'fundamental theorem of calculus'\nand tell me about its main dependencies.\n</code></pre>"},{"location":"getting-started/quickstart/#step-5-observe-the-results","title":"Step 5: Observe the Results","text":"<p>The AI assistant will process your query. It uses the LeanExplore API to search for formal statements related to the 'fundamental theorem of calculus', identify the most relevant one(s), and then find and list their main dependencies. You should expect a conversational response that includes the formal Lean code for the theorem, along with explanations and other contextual information to help you understand its structure and connections within the library.</p>"},{"location":"getting-started/quickstart/#congratulations-next-steps","title":"Congratulations &amp; Next Steps","text":"<p>You've now successfully used LeanExplore to perform a direct API search and to interact with the AI chat assistant! These are two of the primary ways to leverage LeanExplore's capabilities.</p> <p>From here, you can:</p> <ul> <li>Dive deeper into all command-line options in the Using the CLI guide.</li> <li>Learn about using local data and programmatic access (both local and API) in the Performing Searches section.</li> <li>If you're interested in building custom AI agent integrations, explore the MCP (AI Agents) documentation.</li> </ul>"},{"location":"mcp/agents/","title":"LeanExplore MCP Server for AI Agents","text":"<p>LeanExplore includes a Model Context Protocol (MCP) server designed to expose its powerful search and data retrieval functionalities as Tools that AI agents can utilize. This enables developers to build intelligent applications\u2014for example, those using the <code>openai-agents</code> library or other agentic frameworks\u2014that can programmatically interact with and reason about Lean 4 codebases through LeanExplore.</p>"},{"location":"mcp/agents/#contents","title":"Contents","text":"<ul> <li>Overview of the LeanExplore MCP Server</li> <li>Integrating with MCP Client Applications</li> <li>Running the LeanExplore MCP Server</li> <li>Command Invocation</li> <li>Key Command-Line Options</li> <li>Server Behavior</li> <li>Exposed Tools for AI Agents</li> <li>Tool: search</li> <li>Tool: get_by_id</li> <li>Tool: get_dependencies</li> <li>Relationship with leanexplore chat</li> <li>Notes for Custom Agent Developers</li> </ul>"},{"location":"mcp/agents/#overview-of-the-leanexplore-mcp-server","title":"Overview of the LeanExplore MCP Server","text":"<p>The LeanExplore MCP server acts as a dedicated interface for AI agents. It listens for requests, typically formatted as JSON-RPC 2.0 messages, over standard input/output (stdio). When an agent sends a request to use a tool, the server translates this into an action within the LeanExplore system\u2014querying either the remote LeanExplore API or your local data backend, depending on its configuration.</p> <p>After processing the request, the server returns the results to the agent, allowing for a dynamic, programmatic interaction. This server is built using the <code>FastMCP</code> library, part of the broader MCP Python SDK.</p>"},{"location":"mcp/agents/#integrating-with-mcp-client-applications","title":"Integrating with MCP Client Applications","text":"<p>The LeanExplore MCP server can be integrated as a tool provider with various MCP-compatible client applications. These clients allow you to manage and interact with multiple AI tools and models from a unified interface. An example of such an application is Claude Desktop.</p> <p>To configure an MCP client like Claude Desktop to use the LeanExplore MCP server, you typically need to provide a configuration that specifies how to launch the server. Here's an example of what such a configuration would look like in the client application's settings (often a JSON file):</p> <pre><code>{\n  \"mcpServers\": {\n    \"leanexploreAPI\": {\n      \"command\": \"/path/to/your/leanexplore/package\",\n      \"args\": [\n        \"mcp\",\n        \"serve\",\n        \"--backend\",\n        \"api\",\n        \"--api-key\",\n        \"YOUR_ACTUAL_LEANEXPLORE_API_KEY\"\n      ]\n    }\n  }\n}\n</code></pre> <p>After setting up this configuration in your MCP client application, it should be able to list LeanExplore as an available tool provider and use the tools (<code>search</code>, <code>get_by_id</code>, <code>get_dependencies</code>) exposed by the server.</p> <p>For more details on setting up applications like Claude Desktop with MCP servers, refer to their specific documentation. For Claude Desktop, you can find information at their quickstart guide.</p>"},{"location":"mcp/agents/#running-the-leanexplore-mcp-server","title":"Running the LeanExplore MCP Server","text":"<p>You can launch the MCP server directly from the command line using the <code>leanexplore mcp serve</code> command. This command is intended for developers who are building or connecting their own custom MCP client applications or AI agents.</p>"},{"location":"mcp/agents/#command-invocation","title":"Command Invocation","text":"<p>Here are typical ways to start the server:</p> <pre><code># Start server using the API backend (default)\n# Requires LeanExplore API key to be configured or passed via --api-key\nleanexplore mcp serve --backend api\n\n# Start server using your local data backend\n# Requires local data to be fetched via 'leanexplore data fetch'\nleanexplore mcp serve --backend local\n\n# Example with specific API key and debug logging for the API backend\nleanexplore mcp serve --backend api --api-key YOUR_LE_API_KEY --log-level DEBUG\n</code></pre>"},{"location":"mcp/agents/#key-command-line-options","title":"Key Command-Line Options","text":"<ul> <li><code>--backend {api|local}</code> (alias: <code>-b</code>) Determines the data source for the server's tools:</li> <li><code>api</code>: Tools will query the remote LeanExplore API. Prerequisite: A valid LeanExplore API key must be configured (via <code>leanexplore configure api-key</code>) or provided directly using the <code>--api-key</code> option. This backend typically provides access to the most current data and offloads computation.</li> <li><code>local</code>: Tools will use your locally downloaded data assets (SQLite database, FAISS index). Prerequisite: You must first download the data toolchain using <code>leanexplore data fetch</code>. This backend allows for offline use and full control over the data version.</li> <li><code>--api-key TEXT</code> (Optional) If using <code>--backend api</code>, this option allows you to provide the LeanExplore API key directly for the current server session, overriding any globally configured key.</li> <li><code>--log-level {DEBUG|INFO|WARNING|ERROR|CRITICAL}</code> Sets the logging verbosity for the server. Using <code>DEBUG</code> is helpful for troubleshooting. Default is typically <code>ERROR</code> or <code>WARNING</code> to minimize noise.</li> </ul>"},{"location":"mcp/agents/#server-behavior","title":"Server Behavior","text":"<p>When started, the <code>leanexplore mcp serve</code> command runs the server continuously in the foreground. It takes over your terminal's standard input and output (stdio) to communicate with the connected MCP client.</p> <p>To stop the server, the connected client application should typically initiate a disconnect. Alternatively, you can manually terminate the server process in your terminal (usually with Ctrl+C).</p>"},{"location":"mcp/agents/#exposed-tools-for-ai-agents","title":"Exposed Tools for AI Agents","text":"<p>The LeanExplore MCP server makes its core functionalities available to AI agents as callable \"tools\". These tools allow an agent to programmatically search and retrieve information about Lean statements. The structure of the returned data items (referred to as <code>ResultItem</code> below) is consistent across tools that return statement group information.</p> <p>A <code>ResultItem</code> object includes the following fields:</p> <ul> <li><code>id: integer</code> - Unique identifier of the statement group.</li> <li><code>primary_declaration: object | null</code> - Information about the primary declaration:</li> <li><code>lean_name: string | null</code> - The full Lean name (e.g., \"Nat.add\").</li> <li><code>source_file: string</code> - The source file path (e.g., \"Mathlib/Data/Nat/Basic.lean\").</li> <li><code>range_start_line: integer</code> - The starting line number of the statement group in the source file.</li> <li><code>statement_text: string</code> - The full canonical Lean code text of the statement group.</li> <li><code>docstring: string | null</code> - The docstring associated with the statement group, if available.</li> <li><code>informal_description: string | null</code> - An informal, human-readable description, if available.</li> </ul>"},{"location":"mcp/agents/#tool-search","title":"Tool: <code>search</code>","text":"<ul> <li>Purpose: Enables the agent to find Lean statement groups based on a natural language query.</li> <li>Key Parameters:</li> <li><code>query: string</code> (required) - The natural language search query (e.g., \"continuous function\").</li> <li><code>package_filters: string[]</code> (optional) - A list of package names to filter results by (e.g., <code>[\"Mathlib.Analysis\", \"Mathlib.Order\"]</code>). If omitted or empty, no package filter is applied.</li> <li><code>limit: integer</code> (optional, default: 10) - The maximum number of search results to return. Must be a positive integer.</li> <li>Returns: An object containing the search results and metadata, with the following fields:</li> <li><code>query: string</code> - The original search query string submitted.</li> <li><code>packages_applied: string[] | null</code> - List of package filters that were actually applied to the search.</li> <li><code>results: ResultItem[]</code> - A list of <code>ResultItem</code> objects matching the query, structured as described above.</li> <li><code>count: integer</code> - The number of results provided in the <code>results</code> list (respecting the <code>limit</code> parameter).</li> <li><code>total_candidates_considered: integer</code> - The total number of potential candidate results found by the backend before the <code>limit</code> was applied by the tool.</li> <li><code>processing_time_ms: integer</code> - Server-side processing time for the search request in milliseconds.</li> </ul>"},{"location":"mcp/agents/#tool-get_by_id","title":"Tool: <code>get_by_id</code>","text":"<ul> <li>Purpose: Allows the agent to retrieve detailed information for a specific statement group using its unique ID.</li> <li>Key Parameters:</li> <li><code>group_id: integer</code> (required) - The unique identifier of the statement group to retrieve (e.g., <code>12345</code>).</li> <li>Returns: A single <code>ResultItem</code> object (structured as described above) if a statement group with the given ID is found. Returns <code>null</code> if no such group exists.</li> </ul>"},{"location":"mcp/agents/#tool-get_dependencies","title":"Tool: <code>get_dependencies</code>","text":"<ul> <li>Purpose: Enables the agent to fetch the direct dependencies (i.e., items cited by or relied upon) for a given statement group ID.</li> <li>Key Parameters:</li> <li><code>group_id: integer</code> (required) - The unique identifier of the statement group for which to fetch dependencies (e.g., <code>12345</code>).</li> <li>Returns: An object containing the dependencies if found, otherwise <code>null</code>. The object has the following fields:</li> <li><code>source_group_id: integer</code> - The ID of the statement group for which dependencies were requested.</li> <li><code>citations: ResultItem[]</code> - A list of <code>ResultItem</code> objects representing the direct dependencies. Each item is structured as described above.</li> <li><code>count: integer</code> - The number of direct dependencies found and returned in the <code>citations</code> list.</li> </ul> <p>Returns <code>null</code> if the source statement group is not found or has no dependencies.</p> <p>Illustrative Agent Workflow: An AI agent might first use the <code>search</code> tool to discover statements related to a concept (e.g., \"Frobenius homomorphism\"). From the results, it could pick a statement ID that seems most relevant. Then, it might call <code>get_by_id</code> to retrieve the full Lean code for that statement, followed by a call to <code>get_dependencies</code> to understand its immediate context and the definitions it relies on. This sequence allows the agent to gather comprehensive information for reasoning or explanation tasks.</p>"},{"location":"mcp/agents/#relationship-with-leanexplore-chat","title":"Relationship with <code>leanexplore chat</code>","text":"<p>The <code>leanexplore chat</code> command provides a ready-to-use AI assistant for interactive exploration. It's important to understand that this chat command internally manages its own instance of the LeanExplore MCP server and acts as an MCP client to it.</p> <p>Therefore, you do not need to run <code>leanexplore mcp serve</code> separately to use the <code>leanexplore chat</code> feature. The <code>leanexplore mcp serve</code> command is specifically for developers who wish to connect their own custom AI agents or other MCP client applications to LeanExplore's toolset.</p>"},{"location":"mcp/agents/#notes-for-custom-agent-developers","title":"Notes for Custom Agent Developers","text":"<ul> <li>Communication Protocol: The LeanExplore MCP server communicates using JSON-RPC 2.0 messages exchanged over standard input/output (stdio). Your custom agent client must be able to spawn the server process and communicate with it via its stdin/stdout streams.</li> <li>Client Implementation: To interact with this server, you'll need an MCP client. The MCP Python SDK (which provides the <code>mcp</code> library used by LeanExplore) includes utilities like <code>ClientSession</code> and <code>stdio_client</code> for building such clients. Frameworks like <code>openai-agents</code> are also designed to work with MCP-compliant servers.</li> <li>Tool Schemas (Pydantic Models): While this page provides an overview of tool parameters and return structures, the precise definitions are implemented as Pydantic models. Developers needing the exact model schemas (e.g., for robust client-side validation or code generation) should refer to the source code in the <code>lean_explore.shared.models.api.py</code> module (for response data structures like <code>APISearchResultItem</code>, <code>APISearchResponse</code>, <code>APICitationsResponse</code>) and <code>lean_explore.mcp.tools.py</code> (for tool function signatures) within the LeanExplore Python package. The tool names called by the agent (e.g., \"search\") correspond to the function names registered as tools.</li> <li>Troubleshooting Server Issues: If you encounter problems when your custom client interacts with the server, running <code>leanexplore mcp serve</code> with the <code>--log-level DEBUG</code> option can provide verbose logs from the server side, which can be invaluable for diagnosing issues related to server startup, backend connections, or tool execution.</li> </ul> <p>By providing this MCP interface, LeanExplore aims to be a valuable component in the ecosystem of AI tools for mathematical research and Lean development, enabling sophisticated programmatic access to its indexed knowledge base of Lean code.</p>"}]}